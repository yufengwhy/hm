{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from math import log\n",
    "from tqdm import tqdm\n",
    "\n",
    "from importlib import reload\n",
    "import utils;reload(utils)\n",
    "from utils import pmap_multi\n",
    "# Human\n",
    "# Edge：graph_nx_human_L_surface_10k.pickle\n",
    "# X: HCPS403_xtract_bp_10k_L.pickle\n",
    "# Y: HCPS403_myelin_NoOutlier_10k_L.pickle\n",
    "\n",
    "# Macaque\n",
    "# Edge: graph_nx_macaque_L_surface_10k.pickle\n",
    "# X: LN8_xtract_bp_10k_L.pickle\n",
    "# Y: Macaque_actual_myelin_L.pickle\n",
    "\n",
    "def pickle_load(fn):\n",
    "    with open(fn, \"rb\") as input_file:\n",
    "        return np.squeeze(np.array(pickle.load(input_file)))\n",
    "\n",
    "fn_list = ['graph_nx_human_L_surface_10k.pickle', 'HCPS403_xtract_bp_10k_L.pickle', 'HCPS403_myelin_NoOutlier_10k_L.pickle', 'graph_nx_macaque_L_surface_10k.pickle', 'LN8_xtract_bp_10k_L.pickle', 'Macaque_actual_myelin_L.pickle']\n",
    "fn_list = ['data/'+fn for fn in fn_list]\n",
    "ah, xh, yh, am, xm, ym = map(pickle_load, fn_list)\n",
    "\n",
    "ym[~np.isfinite(ym)] = 0  # ym has nan\n",
    "\n",
    "# print(ah.shape, xh.shape, yh.shape, am.shape, xm.shape, ym.shape)\n",
    "# (27969, 2) (403, 9368, 42) (403, 9368) (26934, 2) (8, 9027, 42) (9027,)\n",
    "\n",
    "# import scipy.io\n",
    "# mat = scipy.io.loadmat('data/KL_matrix_L.mat')\n",
    "# arr = mat['KL_matrix_L'].transpose()\n",
    "# sim = np.power(arr, -4)\n",
    "\n",
    "# pd.DataFrame(yh.transpose()).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(data):\n",
    "    row_sum = np.sum(data, axis=1, keepdims=True)\n",
    "    res = np.divide(data, row_sum, out=np.zeros_like(data), where=row_sum!=0)\n",
    "    return res\n",
    "     \n",
    "def log2(A):\n",
    "    # mask 0 for log(0)\n",
    "    return ma.log2(A).filled(0)\n",
    "\n",
    "# KL\n",
    "def my_kl(A, B):\n",
    "    # A (m,p); B (n,p); out (m,n)\n",
    "    A = standardization(A)\n",
    "    B = standardization(B)\n",
    "    return A * log2(A) @ np.ones_like(B.transpose()) - A @ log2(B.transpose()) +\\\n",
    "        np.ones_like(A) @ (B * log2(B)).transpose() - log2(A) @ B.transpose()\n",
    "\n",
    "def my_p(x1, y1, x2, y2, r=-1.2):\n",
    "    # use 2 predict 1\n",
    "    arr = my_kl(x1, x2)  # 9027, 9368\n",
    "    sim = np.power(arr, r)\n",
    "    sim[~np.isfinite(sim)] = 0\n",
    "    p_hm = pd.DataFrame([sim @ y2 / np.sum(sim, axis=1) , y1]).T.corr().to_numpy()[0,1]\n",
    "    return p_hm\n",
    "\n",
    "res = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2m\n",
    "\n",
    "def pair_p(i, j):\n",
    "    return i,j,my_p(xm[i], ym, xm[j], ym, -4)\n",
    "    \n",
    "start, end = 0, xm.shape[0]\n",
    "res['m2m'] = pmap_multi(pair_p, itertools.permutations(range(start, end), 2), backend='multiprocessing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2m\n",
    "def pair_p(i, j):\n",
    "    return i,j,my_p(xm[i], ym, xh[j], yh[j], -4)\n",
    "\n",
    "a, b = range(xm.shape[0]), range(xh.shape[0])\n",
    "res['h2m'] = pmap_multi(pair_p, itertools.product(a, b), backend='multiprocessing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2h\n",
    "def pair_p(i, j):\n",
    "    return i,j,my_p(xh[i], yh[i], xm[j], ym, -4)\n",
    "\n",
    "a, b = range(xh.shape[0]), range(xm.shape[0])\n",
    "res['m2h'] = pmap_multi(pair_p, itertools.product(a, b), backend='multiprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2h\n",
    "def pair_p(i, j):\n",
    "    return i,j,my_p(xh[i], yh[i], xh[j], yh[j], -4)\n",
    "\n",
    "start, end = 0, xh.shape[0] # xh.shape[0] 10\n",
    "res['h2h'] = pmap_multi(pair_p, itertools.permutations(range(start, end), 2), backend='multiprocessing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"res.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(res, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 任意2h相关性\n",
    "# # num_h = yh.shape[0]\n",
    "# # res = np.zeros([num_h,num_h])\n",
    "# s, e = 50, 100\n",
    "# for i,j in tqdm(itertools.permutations(range(s, e), 2)):\n",
    "#     p = my_p(xh[i], yh[i], xh[j], yh[j], -4)\n",
    "#     res[i][j] = round(p, 3)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 复现0.53\n",
    "\n",
    "# xh_mean = xh.mean(axis=0) # 9368, 42\n",
    "# yh_mean = yh.mean(axis=0) # 9368\n",
    "# xm_mean = xm.mean(axis=0) # 9027, 42\n",
    "# my_p(xm_mean, ym, xh_mean, yh_mean, -4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7288f315087fdb0a15835a979a50c8db3e0e21492381bafafe9d84f995bbb7dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
